{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install subprocess\n",
        "!pip install ultralytics\n",
        "!pip install time\n",
        "!pip install speedtest"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N0HK_r0Cz0rA",
        "outputId": "189c54b4-9ad7-43e2-95f7-65de29be7a18"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[31mERROR: Could not find a version that satisfies the requirement subprocess (from versions: none)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for subprocess\u001b[0m\u001b[31m\n",
            "\u001b[0mCollecting ultralytics\n",
            "  Downloading ultralytics-8.3.38-py3-none-any.whl.metadata (35 kB)\n",
            "Requirement already satisfied: numpy>=1.23.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (1.26.4)\n",
            "Requirement already satisfied: matplotlib>=3.3.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (3.8.0)\n",
            "Requirement already satisfied: opencv-python>=4.6.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (4.10.0.84)\n",
            "Requirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (11.0.0)\n",
            "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (6.0.2)\n",
            "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.32.3)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (1.13.1)\n",
            "Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.5.1+cu121)\n",
            "Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (0.20.1+cu121)\n",
            "Requirement already satisfied: tqdm>=4.64.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (4.66.6)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from ultralytics) (5.9.5)\n",
            "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.10/dist-packages (from ultralytics) (9.0.0)\n",
            "Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.2.2)\n",
            "Requirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (0.13.2)\n",
            "Collecting ultralytics-thop>=2.0.0 (from ultralytics)\n",
            "  Downloading ultralytics_thop-2.0.12-py3-none-any.whl.metadata (9.4 kB)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (4.55.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.4.7)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (24.2)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (3.2.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.4->ultralytics) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.4->ultralytics) (2024.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (2024.8.30)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (2024.10.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=1.8.0->ultralytics) (1.3.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.8.0->ultralytics) (3.0.2)\n",
            "Downloading ultralytics-8.3.38-py3-none-any.whl (896 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m896.3/896.3 kB\u001b[0m \u001b[31m18.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ultralytics_thop-2.0.12-py3-none-any.whl (26 kB)\n",
            "Installing collected packages: ultralytics-thop, ultralytics\n",
            "Successfully installed ultralytics-8.3.38 ultralytics-thop-2.0.12\n",
            "\u001b[31mERROR: Could not find a version that satisfies the requirement time (from versions: none)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for time\u001b[0m\u001b[31m\n",
            "\u001b[0mCollecting speedtest\n",
            "  Downloading speedtest-0.0.1-py3-none-any.whl.metadata (200 bytes)\n",
            "Downloading speedtest-0.0.1-py3-none-any.whl (1.3 kB)\n",
            "Installing collected packages: speedtest\n",
            "Successfully installed speedtest-0.0.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "bQjU9sr-VSIn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install speedtest-cli\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Oz7uFnr_0uSK",
        "outputId": "2c0ae200-c619-4fb6-a28b-3334fda6bd7b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: speedtest-cli in /usr/local/lib/python3.10/dist-packages (2.1.3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "BmGMhQQOzUlM",
        "outputId": "8c69ec46-5f33-484c-c5f0-140c1425f0fd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/urllib3/connectionpool.py:1099: InsecureRequestWarning: Unverified HTTPS request is being made to host 'speed.hetzner.de'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Download Speed: 1.95 Kbps\n",
            "Internet speed: 1.95 Kbps\n",
            "Selected quality: 360p\n",
            "Stream URL: https://manifest.googlevideo.com/api/manifest/hls_playlist/expire/1732721175/ei/t-VGZ73QDJf4sfIPis_--A8/ip/34.169.26.140/id/inDzgZjCxmQ.2/itag/93/source/yt_live_broadcast/requiressl/yes/ratebypass/yes/live/1/sgoap/gir%3Dyes%3Bitag%3D140/sgovp/gir%3Dyes%3Bitag%3D134/rqh/1/hdlc/1/hls_chunk_host/rr3---sn-qxoedn7k.googlevideo.com/xpc/EgVo2aDSNQ%3D%3D/playlist_duration/30/manifest_duration/30/spc/qtApAVE8tZGEFeh0Sohy89anI4X6tP_H_tYvzMJObVRCGgL-IttfX8RmIiLNb6Q/vprv/1/playlist_type/DVR/initcwndbps/20843750/met/1732699575,/mh/CV/mm/44/mn/sn-qxoedn7k/ms/lva/mv/m/mvi/3/pl/17/rms/lva,lva/dover/11/pacing/0/keepalive/yes/fexp/51319289,51326932,51335594,51355912/mt/1732699237/sparams/expire,ei,ip,id,itag,source,requiressl,ratebypass,live,sgoap,sgovp,rqh,hdlc,xpc,playlist_duration,manifest_duration,spc,vprv,playlist_type/sig/AJfQdSswRgIhAPUZzU04tdz2CIocKBw-NjsYqiAWyDPWN7kj7Yiv_dpWAiEA7kZ0rPoKrASCuJrngqfe_yOL8Z22oGe-ir7EdkPOgo8%3D/lsparams/hls_chunk_host,initcwndbps,met,mh,mm,mn,ms,mv,mvi,pl,rms/lsig/AGluJ3MwRAIgRdGxJQHOLIoptFqAukd-_vlUAnrvFojV4n2CyFK_h6cCIB1RhUefos60q85hl-c2J_ia3P2nz4aK9lHIt-BwVC44/playlist/index.m3u8\n",
            "\n",
            "0: 384x640 1 eating, 5 lyings, 1 standing, 132.9ms\n",
            "Speed: 4.8ms preprocess, 132.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Eating: 1, Lying: 5, Standing: 1\n",
            "\n",
            "0: 384x640 1 eating, 5 lyings, 1 standing, 134.9ms\n",
            "Speed: 3.4ms preprocess, 134.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Eating: 1, Lying: 5, Standing: 1\n",
            "\n",
            "0: 384x640 1 eating, 5 lyings, 1 standing, 132.2ms\n",
            "Speed: 3.5ms preprocess, 132.2ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Eating: 1, Lying: 5, Standing: 1\n",
            "\n",
            "0: 384x640 1 eating, 5 lyings, 1 standing, 155.5ms\n",
            "Speed: 2.2ms preprocess, 155.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Eating: 1, Lying: 5, Standing: 1\n",
            "\n",
            "0: 384x640 1 eating, 5 lyings, 1 standing, 137.1ms\n",
            "Speed: 5.3ms preprocess, 137.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Eating: 1, Lying: 5, Standing: 1\n",
            "\n",
            "0: 384x640 1 eating, 5 lyings, 1 standing, 143.7ms\n",
            "Speed: 4.0ms preprocess, 143.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Eating: 1, Lying: 5, Standing: 1\n",
            "\n",
            "0: 384x640 1 eating, 5 lyings, 1 standing, 134.7ms\n",
            "Speed: 2.6ms preprocess, 134.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Eating: 1, Lying: 5, Standing: 1\n",
            "\n",
            "0: 384x640 1 eating, 5 lyings, 1 standing, 129.2ms\n",
            "Speed: 4.6ms preprocess, 129.2ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Eating: 1, Lying: 5, Standing: 1\n",
            "\n",
            "0: 384x640 1 eating, 5 lyings, 1 standing, 131.6ms\n",
            "Speed: 1.8ms preprocess, 131.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Eating: 1, Lying: 5, Standing: 1\n",
            "\n",
            "0: 384x640 1 eating, 5 lyings, 1 standing, 183.2ms\n",
            "Speed: 2.0ms preprocess, 183.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Eating: 1, Lying: 5, Standing: 1\n",
            "\n",
            "0: 384x640 1 eating, 5 lyings, 1 standing, 233.1ms\n",
            "Speed: 3.4ms preprocess, 233.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Eating: 1, Lying: 5, Standing: 1\n",
            "\n",
            "0: 384x640 1 eating, 5 lyings, 1 standing, 226.5ms\n",
            "Speed: 2.4ms preprocess, 226.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Eating: 1, Lying: 5, Standing: 1\n",
            "\n",
            "0: 384x640 1 eating, 5 lyings, 1 standing, 218.7ms\n",
            "Speed: 7.0ms preprocess, 218.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Eating: 1, Lying: 5, Standing: 1\n",
            "\n",
            "0: 384x640 1 eating, 5 lyings, 1 standing, 209.1ms\n",
            "Speed: 2.7ms preprocess, 209.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Eating: 1, Lying: 5, Standing: 1\n",
            "\n",
            "0: 384x640 1 eating, 5 lyings, 1 standing, 214.4ms\n",
            "Speed: 2.4ms preprocess, 214.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Eating: 1, Lying: 5, Standing: 1\n",
            "\n",
            "0: 384x640 1 eating, 5 lyings, 1 standing, 220.5ms\n",
            "Speed: 4.3ms preprocess, 220.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Eating: 1, Lying: 5, Standing: 1\n",
            "\n",
            "0: 384x640 1 eating, 5 lyings, 1 standing, 209.5ms\n",
            "Speed: 2.1ms preprocess, 209.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Eating: 1, Lying: 5, Standing: 1\n",
            "\n",
            "0: 384x640 1 eating, 5 lyings, 1 standing, 211.6ms\n",
            "Speed: 2.2ms preprocess, 211.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Eating: 1, Lying: 5, Standing: 1\n",
            "\n",
            "0: 384x640 1 eating, 5 lyings, 1 standing, 220.3ms\n",
            "Speed: 2.5ms preprocess, 220.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Eating: 1, Lying: 5, Standing: 1\n",
            "\n",
            "0: 384x640 1 eating, 5 lyings, 1 standing, 190.8ms\n",
            "Speed: 2.2ms preprocess, 190.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Eating: 1, Lying: 5, Standing: 1\n",
            "\n",
            "0: 384x640 1 eating, 5 lyings, 1 standing, 216.2ms\n",
            "Speed: 2.0ms preprocess, 216.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Eating: 1, Lying: 5, Standing: 1\n",
            "\n",
            "0: 384x640 1 eating, 5 lyings, 1 standing, 205.7ms\n",
            "Speed: 2.1ms preprocess, 205.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Eating: 1, Lying: 5, Standing: 1\n",
            "\n",
            "0: 384x640 1 eating, 5 lyings, 1 standing, 212.0ms\n",
            "Speed: 2.1ms preprocess, 212.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Eating: 1, Lying: 5, Standing: 1\n",
            "\n",
            "0: 384x640 1 eating, 5 lyings, 1 standing, 224.2ms\n",
            "Speed: 3.8ms preprocess, 224.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Eating: 1, Lying: 5, Standing: 1\n",
            "\n",
            "0: 384x640 1 eating, 5 lyings, 1 standing, 223.1ms\n",
            "Speed: 2.5ms preprocess, 223.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Eating: 1, Lying: 5, Standing: 1\n",
            "\n",
            "0: 384x640 1 eating, 5 lyings, 1 standing, 215.8ms\n",
            "Speed: 2.4ms preprocess, 215.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Eating: 1, Lying: 5, Standing: 1\n",
            "\n",
            "0: 384x640 1 eating, 5 lyings, 1 standing, 230.7ms\n",
            "Speed: 2.5ms preprocess, 230.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Eating: 1, Lying: 5, Standing: 1\n",
            "\n",
            "0: 384x640 1 eating, 5 lyings, 1 standing, 234.8ms\n",
            "Speed: 2.6ms preprocess, 234.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Eating: 1, Lying: 5, Standing: 1\n",
            "\n",
            "0: 384x640 1 eating, 5 lyings, 1 standing, 210.0ms\n",
            "Speed: 2.4ms preprocess, 210.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Eating: 1, Lying: 5, Standing: 1\n",
            "\n",
            "0: 384x640 1 eating, 5 lyings, 1 standing, 223.2ms\n",
            "Speed: 2.3ms preprocess, 223.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Eating: 1, Lying: 5, Standing: 1\n",
            "\n",
            "0: 384x640 1 eating, 5 lyings, 1 standing, 187.3ms\n",
            "Speed: 2.2ms preprocess, 187.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Eating: 1, Lying: 5, Standing: 1\n",
            "\n",
            "0: 384x640 1 eating, 5 lyings, 1 standing, 155.9ms\n",
            "Speed: 2.3ms preprocess, 155.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Eating: 1, Lying: 5, Standing: 1\n",
            "\n",
            "0: 384x640 1 eating, 4 lyings, 1 standing, 141.5ms\n",
            "Speed: 3.5ms preprocess, 141.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Eating: 1, Lying: 4, Standing: 1\n",
            "\n",
            "0: 384x640 1 eating, 4 lyings, 1 standing, 140.1ms\n",
            "Speed: 2.4ms preprocess, 140.1ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Eating: 1, Lying: 4, Standing: 1\n",
            "\n",
            "0: 384x640 1 eating, 4 lyings, 1 standing, 135.0ms\n",
            "Speed: 3.8ms preprocess, 135.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Eating: 1, Lying: 4, Standing: 1\n",
            "\n",
            "0: 384x640 1 eating, 4 lyings, 1 standing, 143.1ms\n",
            "Speed: 3.1ms preprocess, 143.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Eating: 1, Lying: 4, Standing: 1\n",
            "\n",
            "0: 384x640 1 eating, 4 lyings, 1 standing, 150.5ms\n",
            "Speed: 2.4ms preprocess, 150.5ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Eating: 1, Lying: 4, Standing: 1\n",
            "\n",
            "0: 384x640 1 eating, 5 lyings, 1 standing, 131.6ms\n",
            "Speed: 3.0ms preprocess, 131.6ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Eating: 1, Lying: 5, Standing: 1\n",
            "\n",
            "0: 384x640 1 eating, 5 lyings, 1 standing, 158.2ms\n",
            "Speed: 3.3ms preprocess, 158.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Eating: 1, Lying: 5, Standing: 1\n",
            "\n",
            "0: 384x640 1 eating, 5 lyings, 1 standing, 141.6ms\n",
            "Speed: 2.6ms preprocess, 141.6ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Eating: 1, Lying: 5, Standing: 1\n",
            "\n",
            "0: 384x640 1 eating, 5 lyings, 1 standing, 136.6ms\n",
            "Speed: 2.3ms preprocess, 136.6ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Eating: 1, Lying: 5, Standing: 1\n",
            "\n",
            "0: 384x640 1 eating, 5 lyings, 1 standing, 139.0ms\n",
            "Speed: 2.6ms preprocess, 139.0ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Eating: 1, Lying: 5, Standing: 1\n",
            "\n",
            "0: 384x640 1 eating, 5 lyings, 1 standing, 157.0ms\n",
            "Speed: 3.6ms preprocess, 157.0ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Eating: 1, Lying: 5, Standing: 1\n",
            "\n",
            "0: 384x640 1 eating, 5 lyings, 1 standing, 139.7ms\n",
            "Speed: 2.4ms preprocess, 139.7ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Eating: 1, Lying: 5, Standing: 1\n",
            "\n",
            "0: 384x640 1 eating, 5 lyings, 1 standing, 183.3ms\n",
            "Speed: 2.5ms preprocess, 183.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Eating: 1, Lying: 5, Standing: 1\n",
            "\n",
            "0: 384x640 1 eating, 5 lyings, 1 standing, 153.4ms\n",
            "Speed: 3.1ms preprocess, 153.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Eating: 1, Lying: 5, Standing: 1\n",
            "\n",
            "0: 384x640 1 eating, 5 lyings, 1 standing, 142.6ms\n",
            "Speed: 3.5ms preprocess, 142.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Eating: 1, Lying: 5, Standing: 1\n",
            "\n",
            "0: 384x640 1 eating, 5 lyings, 1 standing, 139.1ms\n",
            "Speed: 2.8ms preprocess, 139.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Eating: 1, Lying: 5, Standing: 1\n",
            "\n",
            "0: 384x640 1 eating, 5 lyings, 1 standing, 156.7ms\n",
            "Speed: 2.0ms preprocess, 156.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Eating: 1, Lying: 5, Standing: 1\n",
            "\n",
            "0: 384x640 1 eating, 5 lyings, 1 standing, 139.2ms\n",
            "Speed: 2.0ms preprocess, 139.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Eating: 1, Lying: 5, Standing: 1\n",
            "\n",
            "0: 384x640 1 eating, 5 lyings, 1 standing, 169.6ms\n",
            "Speed: 2.2ms preprocess, 169.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Eating: 1, Lying: 5, Standing: 1\n",
            "\n",
            "0: 384x640 1 eating, 5 lyings, 1 standing, 133.1ms\n",
            "Speed: 2.1ms preprocess, 133.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Eating: 1, Lying: 5, Standing: 1\n",
            "\n",
            "0: 384x640 1 eating, 5 lyings, 1 standing, 140.0ms\n",
            "Speed: 2.1ms preprocess, 140.0ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Eating: 1, Lying: 5, Standing: 1\n",
            "\n",
            "0: 384x640 1 eating, 5 lyings, 1 standing, 136.2ms\n",
            "Speed: 2.4ms preprocess, 136.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Eating: 1, Lying: 5, Standing: 1\n",
            "\n",
            "0: 384x640 1 eating, 5 lyings, 1 standing, 136.7ms\n",
            "Speed: 2.4ms preprocess, 136.7ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Eating: 1, Lying: 5, Standing: 1\n",
            "\n",
            "0: 384x640 1 eating, 5 lyings, 1 standing, 152.1ms\n",
            "Speed: 2.5ms preprocess, 152.1ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Eating: 1, Lying: 5, Standing: 1\n",
            "\n",
            "0: 384x640 1 eating, 5 lyings, 1 standing, 163.3ms\n",
            "Speed: 2.4ms preprocess, 163.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Eating: 1, Lying: 5, Standing: 1\n",
            "\n",
            "0: 384x640 1 eating, 5 lyings, 1 standing, 149.3ms\n",
            "Speed: 3.6ms preprocess, 149.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Eating: 1, Lying: 5, Standing: 1\n",
            "\n",
            "0: 384x640 1 eating, 5 lyings, 1 standing, 138.3ms\n",
            "Speed: 2.3ms preprocess, 138.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Eating: 1, Lying: 5, Standing: 1\n",
            "\n",
            "0: 384x640 1 eating, 5 lyings, 1 standing, 134.8ms\n",
            "Speed: 3.1ms preprocess, 134.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Eating: 1, Lying: 5, Standing: 1\n",
            "\n",
            "0: 384x640 1 eating, 5 lyings, 1 standing, 126.7ms\n",
            "Speed: 2.0ms preprocess, 126.7ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Eating: 1, Lying: 5, Standing: 1\n",
            "\n",
            "0: 384x640 1 eating, 5 lyings, 1 standing, 150.0ms\n",
            "Speed: 2.0ms preprocess, 150.0ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Eating: 1, Lying: 5, Standing: 1\n",
            "\n",
            "0: 384x640 1 eating, 5 lyings, 1 standing, 131.9ms\n",
            "Speed: 2.0ms preprocess, 131.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Eating: 1, Lying: 5, Standing: 1\n",
            "\n",
            "0: 384x640 1 eating, 5 lyings, 1 standing, 153.1ms\n",
            "Speed: 2.3ms preprocess, 153.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Eating: 1, Lying: 5, Standing: 1\n",
            "\n",
            "0: 384x640 1 eating, 5 lyings, 1 standing, 140.1ms\n",
            "Speed: 2.0ms preprocess, 140.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Eating: 1, Lying: 5, Standing: 1\n",
            "\n",
            "0: 384x640 1 eating, 5 lyings, 1 standing, 132.5ms\n",
            "Speed: 2.3ms preprocess, 132.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Eating: 1, Lying: 5, Standing: 1\n",
            "\n",
            "0: 384x640 1 eating, 5 lyings, 1 standing, 134.4ms\n",
            "Speed: 2.0ms preprocess, 134.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Eating: 1, Lying: 5, Standing: 1\n",
            "\n",
            "0: 384x640 1 eating, 5 lyings, 1 standing, 137.0ms\n",
            "Speed: 2.0ms preprocess, 137.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Eating: 1, Lying: 5, Standing: 1\n",
            "\n",
            "0: 384x640 1 eating, 5 lyings, 1 standing, 159.2ms\n",
            "Speed: 2.3ms preprocess, 159.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Eating: 1, Lying: 5, Standing: 1\n",
            "\n",
            "0: 384x640 1 eating, 5 lyings, 1 standing, 165.7ms\n",
            "Speed: 2.2ms preprocess, 165.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Eating: 1, Lying: 5, Standing: 1\n",
            "\n",
            "0: 384x640 1 eating, 5 lyings, 1 standing, 137.1ms\n",
            "Speed: 3.0ms preprocess, 137.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Eating: 1, Lying: 5, Standing: 1\n",
            "\n",
            "0: 384x640 1 eating, 5 lyings, 1 standing, 133.4ms\n",
            "Speed: 2.0ms preprocess, 133.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Eating: 1, Lying: 5, Standing: 1\n",
            "\n",
            "0: 384x640 1 eating, 5 lyings, 1 standing, 131.1ms\n",
            "Speed: 2.0ms preprocess, 131.1ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Eating: 1, Lying: 5, Standing: 1\n",
            "\n",
            "0: 384x640 1 eating, 5 lyings, 1 standing, 133.0ms\n",
            "Speed: 2.0ms preprocess, 133.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Eating: 1, Lying: 5, Standing: 1\n",
            "\n",
            "0: 384x640 1 eating, 5 lyings, 1 standing, 133.8ms\n",
            "Speed: 2.4ms preprocess, 133.8ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Eating: 1, Lying: 5, Standing: 1\n",
            "\n",
            "0: 384x640 1 eating, 5 lyings, 1 standing, 145.9ms\n",
            "Speed: 2.1ms preprocess, 145.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Eating: 1, Lying: 5, Standing: 1\n",
            "\n",
            "0: 384x640 1 eating, 5 lyings, 1 standing, 153.7ms\n",
            "Speed: 4.9ms preprocess, 153.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Eating: 1, Lying: 5, Standing: 1\n",
            "\n",
            "0: 384x640 1 eating, 5 lyings, 1 standing, 139.8ms\n",
            "Speed: 3.1ms preprocess, 139.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Eating: 1, Lying: 5, Standing: 1\n",
            "\n",
            "0: 384x640 1 eating, 5 lyings, 1 standing, 131.7ms\n",
            "Speed: 3.9ms preprocess, 131.7ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Eating: 1, Lying: 5, Standing: 1\n",
            "\n",
            "0: 384x640 1 eating, 5 lyings, 1 standing, 136.8ms\n",
            "Speed: 2.7ms preprocess, 136.8ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Eating: 1, Lying: 5, Standing: 1\n",
            "\n",
            "0: 384x640 1 eating, 5 lyings, 1 standing, 144.9ms\n",
            "Speed: 2.8ms preprocess, 144.9ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Eating: 1, Lying: 5, Standing: 1\n",
            "\n",
            "0: 384x640 1 eating, 5 lyings, 1 standing, 154.7ms\n",
            "Speed: 2.5ms preprocess, 154.7ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Eating: 1, Lying: 5, Standing: 1\n",
            "\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-9ceb72a4c37c>\u001b[0m in \u001b[0;36m<cell line: 70>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     96\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m                     \u001b[0;31m# Run YOLO predictions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 98\u001b[0;31m                     \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m                     \u001b[0;31m# Count detected behaviors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ultralytics/engine/model.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, source, stream, **kwargs)\u001b[0m\n\u001b[1;32m    174\u001b[0m             \u001b[0;34m...\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Detected {len(r)} objects in image\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m         \"\"\"\n\u001b[0;32m--> 176\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    177\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ultralytics/engine/model.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, source, stream, predictor, **kwargs)\u001b[0m\n\u001b[1;32m    552\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mprompts\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredictor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"set_prompts\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# for SAM-type models\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    553\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredictor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_prompts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 554\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredictor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_cli\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mis_cli\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredictor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    555\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    556\u001b[0m     def track(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ultralytics/engine/predictor.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, source, model, stream, *args, **kwargs)\u001b[0m\n\u001b[1;32m    171\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstream_inference\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 173\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstream_inference\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# merge list of Result into one\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    174\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpredict_cli\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msource\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/_contextlib.py\u001b[0m in \u001b[0;36mgenerator_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     34\u001b[0m             \u001b[0;31m# Issuing `None` to a generator fires it up\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mctx_factory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m                 \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ultralytics/engine/predictor.py\u001b[0m in \u001b[0;36mstream_inference\u001b[0;34m(self, source, model, *args, **kwargs)\u001b[0m\n\u001b[1;32m    257\u001b[0m                 \u001b[0;31m# Inference\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    258\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mprofilers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 259\u001b[0;31m                     \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minference\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    260\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membed\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m                         \u001b[0;32myield\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mpreds\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mpreds\u001b[0m  \u001b[0;31m# yield embedding tensors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ultralytics/engine/predictor.py\u001b[0m in \u001b[0;36minference\u001b[0;34m(self, im, *args, **kwargs)\u001b[0m\n\u001b[1;32m    141\u001b[0m             \u001b[0;32melse\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m         )\n\u001b[0;32m--> 143\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maugment\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maugment\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvisualize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvisualize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0membed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    144\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpre_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ultralytics/nn/autobackend.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, im, augment, visualize, embed)\u001b[0m\n\u001b[1;32m    524\u001b[0m         \u001b[0;31m# PyTorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    525\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpt\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn_module\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 526\u001b[0;31m             \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maugment\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maugment\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvisualize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvisualize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0membed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0membed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    527\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    528\u001b[0m         \u001b[0;31m# TorchScript\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ultralytics/nn/tasks.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, *args, **kwargs)\u001b[0m\n\u001b[1;32m    110\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# for cases of training and validating while training.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 112\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprofile\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvisualize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maugment\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0membed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ultralytics/nn/tasks.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, profile, visualize, augment, embed)\u001b[0m\n\u001b[1;32m    128\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0maugment\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_predict_augment\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 130\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_predict_once\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprofile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvisualize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0membed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    131\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_predict_once\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprofile\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvisualize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0membed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ultralytics/nn/tasks.py\u001b[0m in \u001b[0;36m_predict_once\u001b[0;34m(self, x, profile, visualize, embed)\u001b[0m\n\u001b[1;32m    149\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mprofile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_profile_one_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 151\u001b[0;31m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# run\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    152\u001b[0m             \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# save output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mvisualize\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ultralytics/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    330\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    331\u001b[0m         \u001b[0;34m\"\"\"Forward pass for the YOLOv8 mask Proto module.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 332\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "import subprocess\n",
        "import cv2\n",
        "from ultralytics import YOLO\n",
        "import time\n",
        "import requests\n",
        "\n",
        "def measure_internet_speed():\n",
        "\n",
        "    try:\n",
        "\n",
        "        test_url = \"https://speed.hetzner.de/10MB.bin\"  # A 10MB file for quick testing\n",
        "\n",
        "\n",
        "        start_time = time.time()\n",
        "\n",
        "\n",
        "        response = requests.get(test_url, stream=True, timeout=10, verify=False)\n",
        "\n",
        "        total_size = 0\n",
        "        for chunk in response.iter_content(chunk_size=8192):  # 8 KB chunks\n",
        "            total_size += len(chunk)\n",
        "            if total_size >= 10 * 1024 * 1024:  # Stop after 10MB\n",
        "                break\n",
        "\n",
        "        end_time = time.time()\n",
        "\n",
        "        # Calculate the time it took to download 10 MB (in seconds)\n",
        "        download_time = end_time - start_time\n",
        "        if download_time <= 0:\n",
        "            print(\"Error: Download time is too fast or too slow. Speed could not be measured.\")\n",
        "            return None\n",
        "\n",
        "        # Calculate download speed in Kbps (kilobits per second)\n",
        "        download_speed_kbps = (total_size * 8) / 1024 / download_time  # Kbps\n",
        "        print(f\"Download Speed: {download_speed_kbps:.2f} Kbps\")\n",
        "\n",
        "        return download_speed_kbps\n",
        "    except Exception as e:\n",
        "        print(f\"Error measuring internet speed: {e}\")\n",
        "        return None\n",
        "\n",
        "def get_stream_url(youtube_url, quality='best'):\n",
        "    \"\"\"Get the YouTube stream URL at the specified quality.\"\"\"\n",
        "    process = subprocess.Popen(\n",
        "        ['streamlink', youtube_url, quality, '--stream-url'],\n",
        "        stdout=subprocess.PIPE,\n",
        "        stderr=subprocess.PIPE\n",
        "    )\n",
        "    stream_url, error = process.communicate()\n",
        "    if error:\n",
        "        raise Exception(f\"Error fetching stream URL: {error.decode('utf-8')}\")\n",
        "    return stream_url.decode('utf-8').strip()\n",
        "\n",
        "def select_quality(speed):\n",
        "    \"\"\"Select video quality based on internet speed in Kbps.\"\"\"\n",
        "    if speed >= 5000:  # 5000 Kbps = 5 Mbps\n",
        "        return '720p'\n",
        "    elif speed >= 2000:  # 2000 Kbps = 2 Mbps\n",
        "        return '480p'\n",
        "    else:\n",
        "        return '360p'\n",
        "\n",
        "# Define the YouTube live stream URL\n",
        "youtube_url = 'https://www.youtube.com/live/inDzgZjCxmQ?si=mGfOsMLhGA-SQcA3'\n",
        "\n",
        "# Load the YOLO model\n",
        "model = YOLO('/content/drive/MyDrive/behavor detection system predictions/best.pt')\n",
        "\n",
        "# Main loop to adjust bitrate and process the stream\n",
        "while True:\n",
        "    # Measure current internet speed\n",
        "    speed = measure_internet_speed()\n",
        "    if speed:\n",
        "        print(f\"Internet speed: {speed:.2f} Kbps\")\n",
        "        # Select quality based on speed\n",
        "        quality = select_quality(speed)\n",
        "        print(f\"Selected quality: {quality}\")\n",
        "\n",
        "        try:\n",
        "            # Get the stream URL for the selected quality\n",
        "            stream_url = get_stream_url(youtube_url, quality)\n",
        "            print(f\"Stream URL: {stream_url}\")\n",
        "        except Exception as e:\n",
        "            print(f\"Error fetching stream: {e}\")\n",
        "            time.sleep(5)\n",
        "            continue\n",
        "\n",
        "        # Capture the stream using OpenCV\n",
        "        cap = cv2.VideoCapture(stream_url)\n",
        "\n",
        "        if not cap.isOpened():\n",
        "            print(\"Error opening video stream\")\n",
        "        else:\n",
        "            while cap.isOpened():\n",
        "                ret, frame = cap.read()\n",
        "                if ret:\n",
        "                    # Run YOLO predictions\n",
        "                    results = model(frame)\n",
        "\n",
        "                    # Count detected behaviors\n",
        "                    cow_counts = {\"eating\": 0, \"lying\": 0, \"standing\": 0}\n",
        "                    for result in results:\n",
        "                        if hasattr(result, 'boxes'):\n",
        "                            for box in result.boxes:\n",
        "                                class_id = int(box.cls[0])\n",
        "                                if class_id == 0:  # Eating\n",
        "                                    cow_counts[\"eating\"] += 1\n",
        "                                elif class_id == 1:  # Lying\n",
        "                                    cow_counts[\"lying\"] += 1\n",
        "                                elif class_id == 2:  # Standing\n",
        "                                    cow_counts[\"standing\"] += 1\n",
        "\n",
        "                    # Print detected counts\n",
        "                    print(f\"Eating: {cow_counts['eating']}, Lying: {cow_counts['lying']}, Standing: {cow_counts['standing']}\")\n",
        "\n",
        "                else:\n",
        "                    break\n",
        "\n",
        "        cap.release()\n",
        "    else:\n",
        "        print(\"Failed to measure internet speed. Retrying...\")\n",
        "\n",
        "    # Wait before re-measuring speed\n",
        "    time.sleep(10)\n"
      ]
    }
  ]
}